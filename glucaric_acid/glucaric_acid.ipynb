{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Required packages\n",
    "import numpy as np\n",
    "from hyperopt import hp, fmin, tpe\n",
    "from scikits.odes.ode import ode\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib.lines import Line2D\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Glucaric Acid Synthesis Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Specification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Color palette\n",
    "orders = ['Open Loop', 'Upstream Repression', 'Downstream Activation', 'Dual Control']\n",
    "palette = {'Open Loop': sns.color_palette()[3], 'Upstream Repression': 'tab:orange', 'Downstream Activation': 'tab:green', 'Dual Control': 'tab:blue', 'Initial':'black'}\n",
    "\n",
    "###Helper functions\n",
    "def michaelismenten(x, vm, km):\n",
    "    return (vm*x)/(km+x)\n",
    "\n",
    "def reversible_michaelismenten(x, y, vm, keq, kmx, kmy):\n",
    "    return (vm*(x - (y/keq)))/(x + kmx*(1+(y/kmy)))\n",
    "\n",
    "def hilleqn(x, vm, n, km):\n",
    "    return (vm*x**n)/(km**n + x**n)\n",
    "\n",
    "def michaelismenten_substrateactivation(x, vm, km, a, ka):\n",
    "    vm_eff = vm * (1+ (a*x)/(ka + x))\n",
    "    return (vm_eff*x)/(km  + x)\n",
    "\n",
    "def activation(x, k, theta, n):\n",
    "    return (k*x**n)/(theta**n + x**n)\n",
    "    \n",
    "def repression(x, k, theta, n):\n",
    "    return (k*theta**n)/(theta**n + x**n)\n",
    "    \n",
    "def loss_biological(j1, j2, alpha1=1E-5, alpha2=1E-2):\n",
    "    loss = alpha1*j1 + alpha2*j2\n",
    "    return j1, j2, loss\n",
    "\n",
    "def name_converter(A):\n",
    "    if A == ((0, 1, 0), (1, 0, 0)):\n",
    "        return 'Dual Control'\n",
    "\n",
    "    elif A == ((0, 0, 1), (0, 0, 1)):\n",
    "        return 'Open Loop'\n",
    "\n",
    "    elif A == ((0, 0, 1), (1, 0, 0)):\n",
    "        return 'Downstream Activation'\n",
    "\n",
    "    elif A == ((0, 1, 0), (0, 0, 1)):\n",
    "        return 'Upstream Repression'\n",
    "    else: return 'Invalid Circuit'\n",
    "\n",
    "###Model definition\n",
    "def glucaric_acid(t, y, ydot, params):\n",
    "\n",
    "    lam = 2.7778E-05\n",
    "    v_pts = 0.1656\n",
    "    vm_pgi = 0.8751\n",
    "    keq_pgi = 0.3\n",
    "    km_pgi_g6p = 0.28\n",
    "    km_pgi_f6p = 0.147\n",
    "    vm_zwf = 0.0853\n",
    "    km_zwf_g6p = 0.1\n",
    "    vm_pfk = 2.615\n",
    "    km_pfk_f6p = 0.16\n",
    "    n_pfk = 3\n",
    "    vm_ino1 = 0.2616\n",
    "    km_ino1_g6p = 1.18\n",
    "    vm_t_mi = 0.045\n",
    "    km_t_mi = 15\n",
    "    vm_miox = 0.2201\n",
    "    km_miox_mi = 24.7\n",
    "    a_miox = 5.4222\n",
    "    ka_miox_mi = 20\n",
    "\n",
    "\n",
    "    g6p, f6p, mi, ino1, miox, j1, j2 = y\n",
    "\n",
    "    A, W = params \n",
    "\n",
    "    n_ino1, theta_ino1, k_ino1 = W[0]\n",
    "    n_miox, theta_miox, k_miox = W[1]\n",
    "\n",
    "    v_pgi = reversible_michaelismenten(g6p, f6p, vm_pgi, keq_pgi, km_pgi_g6p, km_pgi_f6p)\n",
    "    v_zwf = michaelismenten(g6p, vm_zwf, km_zwf_g6p)\n",
    "    v_pfk = hilleqn(f6p, vm_pfk, n_pfk, km_pfk_f6p)\n",
    "    v_ino1 = ino1 * michaelismenten(g6p, vm_ino1, km_ino1_g6p)\n",
    "    v_tm = michaelismenten(mi, vm_t_mi, km_t_mi)\n",
    "    v_miox = miox * michaelismenten_substrateactivation(mi, vm_miox, km_miox_mi, a_miox, ka_miox_mi)\n",
    "\n",
    "    u_ino1_mi = np.sum(A[0]*np.array([activation(mi, k_ino1, theta_ino1, n_ino1), repression(mi, k_ino1, theta_ino1, n_ino1), k_ino1]))\n",
    "    u_miox_mi = np.sum(A[1]*np.array([activation(mi, k_miox, theta_miox, n_miox), repression(mi, k_miox, theta_miox, n_miox), k_miox]))\n",
    "\n",
    "    ydot[0] = v_pts - v_zwf - v_pgi - lam*g6p\n",
    "    ydot[1] = v_pgi + 0.5*v_zwf - v_pfk - lam*f6p\n",
    "    ydot[2] = v_ino1 - v_tm - v_miox - lam*mi\n",
    "    ydot[3] = u_ino1_mi  - lam*ino1\n",
    "    ydot[4] = u_miox_mi - lam*miox\n",
    "    ydot[5] = (v_pts - v_miox)**2\n",
    "    ydot[6] = u_ino1_mi + u_miox_mi\n",
    "\n",
    "###Define search space\n",
    "space = hp.choice('architecture', \n",
    "    [([[0, 0, 1], [1, 0, 0]], [[2., hp.uniform('theta1_da', 1E-7, 10), hp.uniform('k1_da', 1E-7, 5)], [2., hp.uniform('theta2_da', 1E-7, 10), hp.uniform('k2_da', 1E-7, 5)]]),\n",
    "     ([[0, 1, 0], [0, 0, 1]], [[2., hp.uniform('theta1_ur', 1E-7, 10), hp.uniform('k1_ur', 1E-7, 5)], [2., hp.uniform('theta2_ur', 1E-7, 10), hp.uniform('k2_ur', 1E-7, 5)]]),\n",
    "     ([[0, 0, 1], [0, 0, 1]], [[2., hp.uniform('theta1_nc', 1E-7, 10), hp.uniform('k1_nc', 1E-7, 5)], [2., hp.uniform('theta2_nc', 1E-7, 10), hp.uniform('k2_nc', 1E-7, 5)]]),\n",
    "     ([[0, 1, 0], [1, 0, 0]], [[2., hp.uniform('theta1_dc', 1E-7, 10), hp.uniform('k1_dc', 1E-7, 5)], [2., hp.uniform('theta2_dc', 1E-7, 10), hp.uniform('k2_dc', 1E-7, 5)]])])\n",
    "\n",
    "###Objective function\n",
    "def run_hyperopt(max_iters):\n",
    "    losses = []\n",
    "    params = []\n",
    "    circuits = []\n",
    "\n",
    "    #Define objective function\n",
    "    def objective(args):\n",
    "        architecture, param_values = args\n",
    "        #Integration conditions\n",
    "        t = np.linspace(0, 5E5, 200) \n",
    "        y0 = np.array([0.281, 0.0605, 0., 0., 0. , 0., 0.]) #g6p, f6p, mi, ino1, miox\n",
    "\n",
    "        extra_options = {'old_api': False, 'user_data': [architecture, param_values], 'rtol':1E-4}\n",
    "        ode_solver = ode('cvode', glucaric_acid, **extra_options)\n",
    "        solution = ode_solver.solve(t, y0)\n",
    "        j1, j2 = solution.values.y[-1, -2:]\n",
    "        j1, j2, loss = loss_biological(j1, j2, alpha1=1E-5, alpha2=1E-3)\n",
    "        losses.append(loss)\n",
    "        params.append(param_values)\n",
    "        circuits.append(architecture)\n",
    "        return loss\n",
    "    \n",
    "\n",
    "    #Run hyperopt call\n",
    "    best = fmin(objective, space, algo=tpe.suggest, max_evals=max_iters)\n",
    "    #Create trajectory data frame\n",
    "    landscape = pd.DataFrame({'circuit':circuits, 'loss': losses, 'k1': [params[i][0][2] for i in range(len(params))], 'k2': [params[i][1][2] for i in range(len(params))], 'theta1': [params[i][0][1] for i in range(len(params))], 'theta2': [params[i][1][1] for i in range(len(params))]})  \n",
    "    landscape['Circuit'] = [name_converter(landscape.circuit[i]) for i in range(len(landscape))]\n",
    "    landscape = landscape.reset_index()\n",
    "\n",
    "    best_loss = 1E5\n",
    "    best_circuit = 'Initial'\n",
    "    best_losses = []\n",
    "    best_losses_circuits = []\n",
    "    for i in range(len(landscape)):\n",
    "        if landscape.loss[i] < best_loss:\n",
    "            best_loss = landscape.loss[i]\n",
    "            best_circuit = landscape.Circuit[i]\n",
    "        best_losses.append(best_loss)\n",
    "        best_losses_circuits.append(best_circuit)\n",
    "    landscape['best_losses'] = best_losses\n",
    "    landscape['best_loss_circuit'] = best_losses_circuits\n",
    "\n",
    "    return landscape, best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulation Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Run sample optimization\n",
    "max_iters = 10\n",
    "landscape, best = run_hyperopt(max_iters)\n",
    "#landscape.to_csv('sample_run.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Explore kinetic perturbations - VERY TIME CONSUMING\n",
    "global perturbs\n",
    "max_iters = 1000\n",
    "total_landscape =  pd.DataFrame()\n",
    "total_perturbs = lhs(3, samples=1000)\n",
    "for p in total_perturbs:\n",
    "    perturbs = p\n",
    "    space = hp.choice('architecture', \n",
    "    [([[0, 0, 1], [1, 0, 0]], [[2., hp.uniform('theta1_da', 1E-7, 10), hp.uniform('k1_da', 1E-7, 5)], [2., hp.uniform('theta2_da', 1E-7, 10), hp.uniform('k2_da', 1E-7, 5)]])])\n",
    "    da_landscape, best = run_hyperopt(max_iters)\n",
    "\n",
    "    space = hp.choice('architecture', \n",
    "    [([[0, 1, 0], [0, 0, 1]], [[2., hp.uniform('theta1_ur', 1E-7, 10), hp.uniform('k1_ur', 1E-7, 5)], [2., hp.uniform('theta2_ur', 1E-7, 10), hp.uniform('k2_ur', 1E-7, 5)]])])\n",
    "    ur_landscape, best = run_hyperopt(max_iters)\n",
    "\n",
    "    space = hp.choice('architecture', \n",
    "    [([[0, 0, 1], [0, 0, 1]], [[2., hp.uniform('theta1_nc', 1E-7, 10), hp.uniform('k1_nc', 1E-7, 5)], [2., hp.uniform('theta2_nc', 1E-7, 10), hp.uniform('k2_nc', 1E-7, 5)]])])\n",
    "    nc_landscape, best = run_hyperopt(max_iters)\n",
    "\n",
    "    space = hp.choice('architecture', \n",
    "    [([[0, 1, 0], [1, 0, 0]], [[2., hp.uniform('theta1_dc', 1E-7, 10), hp.uniform('k1_dc', 1E-7, 5)], [2., hp.uniform('theta2_dc', 1E-7, 10), hp.uniform('k2_dc', 1E-7, 5)]])])\n",
    "    dc_landscape, best = run_hyperopt(max_iters)\n",
    "\n",
    "    landscape = pd.concat([dc_landscape, nc_landscape, ur_landscape, da_landscape])\n",
    "    total_landscape = pd.concat([total_landscape, landscape])\n",
    "    landscape.to_csv('kinetic_perturbation.csv', mode='a')\n",
    "    \n",
    "total_landscape.to_csv('kinetic_perturbation_total.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Explore growth conditions robustness \n",
    "global perturbs\n",
    "max_iters = 1000\n",
    "total_landscape = pd.DataFrame()\n",
    "total_perturbs = lhs(2, samples=500)\n",
    "for p in total_perturbs:\n",
    "    perturbs = p\n",
    "    space = hp.choice('architecture', \n",
    "    [([[0, 1, 0], [0, 0, 1]], [[2., hp.uniform('theta1_ur', 1E-7, 10), hp.uniform('k1_ur', 1E-7, 5)], [2., hp.uniform('theta2_ur', 1E-7, 10), hp.uniform('k2_ur', 1E-7, 5)]])])\n",
    "    ur_landscape, best = run_hyperopt(max_iters)\n",
    "\n",
    "    space = hp.choice('architecture', \n",
    "    [([[0, 0, 1], [1, 0, 0]], [[2., hp.uniform('theta1_da', 1E-7, 10), hp.uniform('k1_da', 1E-7, 5)], [2., hp.uniform('theta2_da', 1E-7, 10), hp.uniform('k2_da', 1E-7, 5)]])])\n",
    "    da_landscape, best = run_hyperopt(max_iters)\n",
    "\n",
    "    space = hp.choice('architecture', \n",
    "    [([[0, 1, 0], [1, 0, 0]], [[2., hp.uniform('theta1_dc', 1E-7, 10), hp.uniform('k1_dc', 1E-7, 5)], [2., hp.uniform('theta2_dc', 1E-7, 10), hp.uniform('k2_dc', 1E-7, 5)]])])\n",
    "    dc_landscape, best = run_hyperopt(max_iters)\n",
    "\n",
    "    space = hp.choice('architecture', \n",
    "    [([[0, 0, 1], [0, 0, 1]], [[2., hp.uniform('theta1_nc', 1E-7, 10), hp.uniform('k1_nc', 1E-7, 5)], [2., hp.uniform('theta2_nc', 1E-7, 10), hp.uniform('k2_nc', 1E-7, 5)]])])\n",
    "    nc_landscape, best = run_hyperopt(max_iters)\n",
    "\n",
    "    landscape = pd.concat([ur_landscape, da_landscape, dc_landscape, nc_landscape])\n",
    "    landscape['perturb0'] = p[0]\n",
    "    landscape['perturb1'] = p[1]\n",
    "    landscape.to_csv('growth_condition_robustness1.csv', mode='a', header=False)\n",
    "    total_landscape = pd.concat([total_landscape, landscape])\n",
    "\n",
    "total_landscape.to_csv('growth_conditions_robustness_backup1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Explore growth conditions robustness - 1D sweep\n",
    "global perturbs\n",
    "max_iters = 1000\n",
    "total_landscape = pd.DataFrame()\n",
    "total_perturbs = np.linspace(0.5, 2, 101)\n",
    "for p in total_perturbs:\n",
    "    perturbs = [p, 1.]\n",
    "    space = hp.choice('architecture', \n",
    "    [([[0, 1, 0], [0, 0, 1]], [[2., hp.uniform('theta1_ur', 1E-7, 10), hp.uniform('k1_ur', 1E-7, 5)], [2., hp.uniform('theta2_ur', 1E-7, 10), hp.uniform('k2_ur', 1E-7, 5)]])])\n",
    "    ur_landscape, best = run_hyperopt(max_iters)\n",
    "\n",
    "    space = hp.choice('architecture', \n",
    "    [([[0, 0, 1], [1, 0, 0]], [[2., hp.uniform('theta1_da', 1E-7, 10), hp.uniform('k1_da', 1E-7, 5)], [2., hp.uniform('theta2_da', 1E-7, 10), hp.uniform('k2_da', 1E-7, 5)]])])\n",
    "    da_landscape, best = run_hyperopt(max_iters)\n",
    "\n",
    "    space = hp.choice('architecture', \n",
    "    [([[0, 1, 0], [1, 0, 0]], [[2., hp.uniform('theta1_dc', 1E-7, 10), hp.uniform('k1_dc', 1E-7, 5)], [2., hp.uniform('theta2_dc', 1E-7, 10), hp.uniform('k2_dc', 1E-7, 5)]])])\n",
    "    dc_landscape, best = run_hyperopt(max_iters)\n",
    "\n",
    "    space = hp.choice('architecture', \n",
    "    [([[0, 0, 1], [0, 0, 1]], [[2., hp.uniform('theta1_nc', 1E-7, 10), hp.uniform('k1_nc', 1E-7, 5)], [2., hp.uniform('theta2_nc', 1E-7, 10), hp.uniform('k2_nc', 1E-7, 5)]])])\n",
    "    nc_landscape, best = run_hyperopt(max_iters)\n",
    "\n",
    "    landscape = pd.concat([ur_landscape, da_landscape, dc_landscape, nc_landscape])\n",
    "    landscape['perturbation'] = p\n",
    "    landscape.to_csv('gc_influx.csv', mode='a', header=False)\n",
    "    total_landscape = pd.concat([total_landscape, landscape])\n",
    "\n",
    "total_landscape.to_csv('gc_influx_total.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Explore growth conditions robustness - 1D sweep\n",
    "global perturbs\n",
    "max_iters = 1000\n",
    "total_landscape = pd.DataFrame()\n",
    "total_perturbs = np.linspace(0.5, 2, 101)\n",
    "for p in total_perturbs:\n",
    "    perturbs = [1., p]\n",
    "    space = hp.choice('architecture', \n",
    "    [([[0, 1, 0], [0, 0, 1]], [[2., hp.uniform('theta1_ur', 1E-7, 10), hp.uniform('k1_ur', 1E-7, 5)], [2., hp.uniform('theta2_ur', 1E-7, 10), hp.uniform('k2_ur', 1E-7, 5)]])])\n",
    "    ur_landscape, best = run_hyperopt(max_iters)\n",
    "\n",
    "    space = hp.choice('architecture', \n",
    "    [([[0, 0, 1], [1, 0, 0]], [[2., hp.uniform('theta1_da', 1E-7, 10), hp.uniform('k1_da', 1E-7, 5)], [2., hp.uniform('theta2_da', 1E-7, 10), hp.uniform('k2_da', 1E-7, 5)]])])\n",
    "    da_landscape, best = run_hyperopt(max_iters)\n",
    "\n",
    "    space = hp.choice('architecture', \n",
    "    [([[0, 1, 0], [1, 0, 0]], [[2., hp.uniform('theta1_dc', 1E-7, 10), hp.uniform('k1_dc', 1E-7, 5)], [2., hp.uniform('theta2_dc', 1E-7, 10), hp.uniform('k2_dc', 1E-7, 5)]])])\n",
    "    dc_landscape, best = run_hyperopt(max_iters)\n",
    "\n",
    "    space = hp.choice('architecture', \n",
    "    [([[0, 0, 1], [0, 0, 1]], [[2., hp.uniform('theta1_nc', 1E-7, 10), hp.uniform('k1_nc', 1E-7, 5)], [2., hp.uniform('theta2_nc', 1E-7, 10), hp.uniform('k2_nc', 1E-7, 5)]])])\n",
    "    nc_landscape, best = run_hyperopt(max_iters)\n",
    "\n",
    "    landscape = pd.concat([ur_landscape, da_landscape, dc_landscape, nc_landscape])\n",
    "    landscape['perturbation'] = p\n",
    "    landscape.to_csv('gc_export.csv', mode='a', header=False)\n",
    "    total_landscape = pd.concat([total_landscape, landscape])\n",
    "\n",
    "total_landscape.to_csv('gc_export_total.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Run hyperopt 100 times to solve for background\n",
    "max_iters = 1000\n",
    "total_background =  pd.DataFrame()\n",
    "perturbs = [1., 1., 1.]\n",
    "for i in range(100):\n",
    "    space = hp.choice('architecture', \n",
    "    [([[0, 0, 1], [1, 0, 0]], [[2., hp.uniform('theta1_da', 1E-7, 10), hp.uniform('k1_da', 1E-7, 5)], [2., hp.uniform('theta2_da', 1E-7, 10), hp.uniform('k2_da', 1E-7, 5)]])])\n",
    "    da_landscape, best = run_hyperopt(max_iters)\n",
    "\n",
    "    space = hp.choice('architecture', \n",
    "    [([[0, 1, 0], [0, 0, 1]], [[2., hp.uniform('theta1_ur', 1E-7, 10), hp.uniform('k1_ur', 1E-7, 5)], [2., hp.uniform('theta2_ur', 1E-7, 10), hp.uniform('k2_ur', 1E-7, 5)]])])\n",
    "    ur_landscape, best = run_hyperopt(max_iters)\n",
    "\n",
    "    space = hp.choice('architecture', \n",
    "    [([[0, 0, 1], [0, 0, 1]], [[2., hp.uniform('theta1_nc', 1E-7, 10), hp.uniform('k1_nc', 1E-7, 5)], [2., hp.uniform('theta2_nc', 1E-7, 10), hp.uniform('k2_nc', 1E-7, 5)]])])\n",
    "    nc_landscape, best = run_hyperopt(max_iters)\n",
    "\n",
    "    space = hp.choice('architecture', \n",
    "    [([[0, 1, 0], [1, 0, 0]], [[2., hp.uniform('theta1_dc', 1E-7, 10), hp.uniform('k1_dc', 1E-7, 5)], [2., hp.uniform('theta2_dc', 1E-7, 10), hp.uniform('k2_dc', 1E-7, 5)]])])\n",
    "    dc_landscape, best = run_hyperopt(max_iters)\n",
    "\n",
    "    background = pd.concat([dc_landscape, nc_landscape, ur_landscape, da_landscape])\n",
    "    total_background = pd.concat([total_background, background])\n",
    "    #background.to_csv('background.csv', mode='a')\n",
    "    \n",
    "total_background.to_csv('background_total.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####FIGURE: Sample loss descent\n",
    "landscape = pd.read_csv('sample_run.csv')\n",
    "fig, ax = plt.subplots(1,1,figsize=(8, 4))\n",
    "prev_c = 'Initial'\n",
    "starts = []\n",
    "archs = [prev_c]\n",
    "for i in range(len(landscape)):\n",
    "    c = landscape.best_loss_circuit[i]\n",
    "    if c != prev_c: \n",
    "        starts.append(i)\n",
    "        archs.append(c)\n",
    "        prev_c = c\n",
    "starts\n",
    "stops = starts[1:]\n",
    "stops.append(len(landscape))\n",
    "\n",
    "for start, stop, a in zip(starts, stops, archs[1:]):\n",
    "    ax.plot(landscape.index[start:stop+1], landscape.best_losses[start:stop+1], color=palette[a], linewidth=3)\n",
    "ax.set_ylabel('Objective Function Value (log)', fontsize=14)\n",
    "ax.set_yscale('log')\n",
    "ax.set_xlabel('Number of Iterations', fontsize=14)\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig('sample_loss_descent.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####FIGURE: Sample loss scatter and pie\n",
    "fig = plt.figure(figsize=(8, 6))\n",
    "gs = gridspec.GridSpec(nrows=2, ncols=4, height_ratios=[1, 4], width_ratios=[1, 1, 1, 1])\n",
    "\n",
    "ax = fig.add_subplot(gs[1, :])\n",
    "ax.set_xlabel('Number of Iterations', fontsize=14)\n",
    "ax.set_yscale('log')\n",
    "ax.set_ylim([10E-2, 10E8])\n",
    "sns.scatterplot(x='index', y='loss', hue='Circuit', data=landscape, ax=ax, hue_order=orders, palette=palette, legend=False)\n",
    "ax.vlines(250, 0, 10E9, linestyles='dashed')\n",
    "ax.vlines(500, 0, 10E9, linestyles='dashed')\n",
    "ax.vlines(750, 0, 10E9, linestyles='dashed')\n",
    "ax.set_ylabel(None)\n",
    "\n",
    "\n",
    "quarter1 = (landscape.iloc[0:250].sort_values(by='Circuit').groupby('Circuit').count().loss/250).reset_index()\n",
    "quarter2 = (landscape.iloc[250:500].sort_values(by='Circuit').groupby('Circuit').count().loss/250).reset_index()\n",
    "quarter3 = (landscape.iloc[500:750].sort_values(by='Circuit').groupby('Circuit').count().loss/250).reset_index()\n",
    "quarter4 = (landscape.iloc[750:1000].sort_values(by='Circuit').groupby('Circuit').count().loss/250).reset_index()\n",
    "colors = ['tab:green', 'tab:blue', sns.color_palette()[3],  'tab:orange']\n",
    "\n",
    "ax = fig.add_subplot(gs[0, 0])\n",
    "ax.pie(quarter1.loss, colors=colors)\n",
    "\n",
    "ax = fig.add_subplot(gs[0, 1])\n",
    "ax.pie(quarter2.loss, colors=colors)\n",
    "\n",
    "ax = fig.add_subplot(gs[0, 2])\n",
    "ax.pie(quarter3.loss, colors=colors)\n",
    "\n",
    "ax = fig.add_subplot(gs[0, 3])\n",
    "ax.pie(quarter4.loss, colors=colors)\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig('sample_loss_scatter_pie.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Postprocessing on landscape\n",
    "kinetic_perturbation = pd.read_csv('kinetic_perturbation_total.csv')\n",
    "#Recompute best loss on non-error samples\n",
    "start=0\n",
    "stop=1000\n",
    "new_total_landscape = pd.DataFrame()\n",
    "for j in range(500*4):\n",
    "    landscape = kinetic_perturbation.iloc[start:stop].reset_index(drop=True)\n",
    "    best_loss = 1E9\n",
    "    best_circuit = 'Initial'\n",
    "    best_losses = []\n",
    "    best_losses_circuits = []\n",
    "    for i in range(len(landscape)):\n",
    "        if landscape.loss[i] < best_loss and landscape.loss[i] != 0:\n",
    "            best_loss = landscape.loss[i]\n",
    "            best_circuit = landscape.circuit[i]\n",
    "        best_losses.append(best_loss)\n",
    "        best_losses_circuits.append(best_circuit)\n",
    "    landscape['best_losses'] = best_losses\n",
    "    landscape['best_loss_circuit'] = best_losses_circuits \n",
    "    new_total_landscape = pd.concat([new_total_landscape, landscape])\n",
    "    start = stop\n",
    "    stop += 1000\n",
    "kinetic_perturbation = new_total_landscape.loc[new_total_landscape.loss != 0]\n",
    "\n",
    "#Read in background\n",
    "total_background = pd.read_csv('background.csv')\n",
    "plot_landscape = kinetic_perturbation.loc[kinetic_perturbation.index==999]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analysis of Kinetic Perturbation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Figure: Mean loss by architecture\n",
    "fig, axs = plt.subplots(1,4,figsize=(15, 5))\n",
    "palettes = ['Reds', 'Oranges', 'Greens', 'Blues']\n",
    "\n",
    "for i in range(4):\n",
    "    c = orders[i]\n",
    "    da_background = total_background.loc[total_background.Circuit == c].loc[total_background['index'] == 999]\n",
    "    da_landscape =  plot_landscape.loc[plot_landscape.Circuit == c]\n",
    "\n",
    "    plot_data = pd.DataFrame({'best_loss': da_landscape.best_losses.to_list(), 'type':'Perturbed'})\n",
    "    plot_data = pd.concat([plot_data, pd.DataFrame({'best_loss':da_background.best_losses.to_list(), 'type':'Background' })])\n",
    "    \n",
    "    ax = axs[i]\n",
    "    sns.barplot(data=plot_data, y='best_loss', x='type', palette=palettes[i], ax=ax)\n",
    "    ax.set_ylabel('Best Objective Function Value Achieved', fontsize=14)\n",
    "    ax.set_xlabel('')\n",
    "    ax.tick_params(axis='x', labelsize=14)\n",
    "\n",
    "    ax.spines['bottom'].set_visible(False)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.set_xticks([])\n",
    "\n",
    "    if i != 0:  \n",
    "        ax.set_ylabel('')\n",
    "\n",
    "axs[0].set_yticks([0, 2, 4, 6, 8, 10])\n",
    "axs[1].set_yticks([0.25, 0.5, 0.75, 1.0, 1.25, 1.5])\n",
    "axs[2].set_yticks([0.25, 0.5, 0.75, 1.0, 1.25, 1.5])\n",
    "axs[3].set_yticks([0.025, 0.05, 0.075, 0.1, 0.125, 0.15])\n",
    "\n",
    "fig.text(0.11, -0.02, 'Open Loop                                   Upstream Repression                      Downstream Activation                               Dual Control', ha='left', fontsize=14)\n",
    "fig.add_artist(Line2D([0.04, 1], [0.05, 0.05], color='k', linewidth=1))\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig('kinetic_perturbation_loss_bar.png', dpi=300, pad_inches=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Figure: Box plots of parameter values \n",
    "fig, axs = plt.subplots(2,4,figsize=(12, 6), sharey='row')\n",
    "palettes = ['Reds', 'Oranges', 'Greens', 'Blues']\n",
    "params = ['k1', 'theta1', 'k2', 'theta2']\n",
    "param_names = ['$k_1$', r'$\\theta_1$', '$k_2$', r'$\\theta_2$']\n",
    "for i in range(4):\n",
    "    c = orders[i]\n",
    "    background = total_background.loc[total_background.Circuit == c].loc[total_background['index'] == 999]\n",
    "    landscape =  plot_landscape.loc[plot_landscape.Circuit == c]\n",
    "    plot_data = pd.concat([pd.DataFrame({'param':landscape.k1.to_list(), 'type':'Perturbed', 'name': param_names[0]}), pd.DataFrame({'param': landscape.theta1.to_list(), 'type':'Perturbed', 'name': param_names[1]}), pd.DataFrame({'param': landscape.k2.to_list(), 'type':'Perturbed', 'name': param_names[2]}), pd.DataFrame({'param': landscape.theta2.to_list(), 'type':'Perturbed', 'name': param_names[3]})])\n",
    "    plot_background = pd.concat([pd.DataFrame({'param':background.k1.to_list(), 'type':'Background', 'name': param_names[0]}), pd.DataFrame({'param': background.theta1.to_list(), 'type':'Background', 'name': param_names[1]}), pd.DataFrame({'param': background.k2.to_list(), 'type':'Background', 'name': param_names[2]}), pd.DataFrame({'param': background.theta2.to_list(), 'type':'Background', 'name': param_names[3]})])\n",
    "    plot_data = pd.concat([plot_data, plot_background])\n",
    "\n",
    "    for j in range(2):\n",
    "        if j == 0:\n",
    "            subset = plot_data.loc[plot_data.name.isin([param_names[0], param_names[2]])]\n",
    "        else:\n",
    "            subset = plot_data.loc[plot_data.name.isin([param_names[1], param_names[3]])] \n",
    "        ax = axs[j][i]\n",
    "        sns.boxplot(data=subset, y='param', x='name', hue='type', palette=palettes[i], ax=ax, dodge=True)\n",
    "        ax.legend([], [], frameon=False)\n",
    "        ax.set_ylabel(param_names[i], fontsize=14)\n",
    "        ax.set_xlabel('')\n",
    "        ax.tick_params(axis='x', labelsize=14)\n",
    "\n",
    "        ax.spines['bottom'].set_visible(False)\n",
    "        ax.spines['top'].set_visible(False)\n",
    "        ax.spines['right'].set_visible(False)\n",
    "\n",
    "        if i != 0: \n",
    "            ax.spines['left'].set_visible(False) \n",
    "            ax.set_ylabel('')\n",
    "            axs[j][i].tick_params(axis='y', which='both',left=False)\n",
    "        if j == 0:\n",
    "            axs[j][i].tick_params(axis='x', which='both',bottom=False)\n",
    "axs[0][0].set_ylabel('K values', fontsize=14)\n",
    "axs[1][0].set_ylabel(r'$\\theta$ values', fontsize=14)\n",
    "fig.add_artist(Line2D([0.058, 1], [0.09, 0.09], color='k', linewidth=1))\n",
    "fig.add_artist(Line2D([0.057, 1], [0.56, 0.56], color='k', linewidth=1))\n",
    "axs[0][0].set_yticks([0,2, 4, 6])\n",
    "axs[0][0].set_ylim([-0.1, 6])\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig('kinetic_perturbation_param_box.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Run PCA and T-SNE\n",
    "features = ['k1', 'k2', 'theta1', 'theta2']\n",
    "background = total_background.loc[total_background['index'] == 999]\n",
    "background['perturbed'] = [False for i in range(len(background))]\n",
    "perturbed = plot_landscape\n",
    "perturbed['perturbed'] =  [True for i in range(len(perturbed))]\n",
    "combined = pd.concat([background, perturbed])\n",
    "x = combined.loc[:, features].values\n",
    "#Normalize features\n",
    "x = StandardScaler().fit_transform(x)\n",
    "#Run PCA\n",
    "pca = PCA(n_components=2)\n",
    "principalComponents = pca.fit_transform(x)\n",
    "principalDf = pd.DataFrame(data = principalComponents\n",
    "             , columns = ['pc1', 'pc2'])\n",
    "combined['pc1'] = principalComponents[:,0]\n",
    "combined['pc2'] = principalComponents[:,1]\n",
    "\n",
    "tsne = TSNE(n_components=2, verbose=1, perplexity=40, n_iter=300, init='pca')\n",
    "tsne_results = tsne.fit_transform(x)\n",
    "combined['tsne1'] = tsne_results[:,0]\n",
    "combined['tsne2'] = tsne_results[:,1]\n",
    "\n",
    "perturbed = combined.loc[combined.perturbed == True].sort_values(by='Circuit').reset_index(drop=True)\n",
    "background = combined.loc[combined.perturbed == False].sort_values(by='Circuit').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Figure: PCA results\n",
    "fig, axs = plt.subplots(1,1,figsize=(5,5))\n",
    "ax = axs\n",
    "sns.scatterplot(x=\"pc1\", y=\"pc2\", data=perturbed, hue='Circuit', ax=ax, legend=False, alpha=0.5)\n",
    "sns.kdeplot(data=background, x=\"pc1\", y=\"pc2\", hue=\"Circuit\", thresh=.1, ax=ax, alpha=0.5, legend=False)\n",
    "ax.set_ylabel('Principal Component 1', fontsize=14)\n",
    "ax.set_xlabel('Principal Component 2', fontsize=14)\n",
    "fig.tight_layout()\n",
    "fig.savefig('kinetic_perturbation_pca.png', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Growth Condition Robustness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "background = total_background.loc[total_background['index'] == 999]\n",
    "influx = pd.read_csv('gc_influx_total.csv')\n",
    "influx = influx.loc[influx['index'] == 999]\n",
    "export = pd.read_csv('gc_export_total.csv')\n",
    "export = export.loc[export['index'] == 999]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow([[ (0.30196078431372547, 0.6862745098039216, 0.2901960784313726)]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Figure: Influx scan\n",
    "archs = ['Downstream Activation', 'Dual Control', 'Open Loop', 'Upstream Repression' ]\n",
    "colors = [ (0.30196078431372547, 0.6862745098039216, 0.2901960784313726),\n",
    " (0.21568627450980393, 0.49411764705882355, 0.7215686274509804),\n",
    " (0.8941176470588236, 0.10196078431372549, 0.10980392156862745), (1.0, 0.4980392156862745, 0.0)]\n",
    "\n",
    "export['scaledperturb']= 100*(export.perturbation - 1)/1\n",
    "influx['scaledperturb']= 100*(influx.perturbation - 1)/1\n",
    "influx = influx.sort_values(by='Circuit')\n",
    "export = export.sort_values(by='Circuit')\n",
    "\n",
    "fig, axs = plt.subplots(1,2,figsize=(10, 5), sharey=True)\n",
    "for i in range(4):\n",
    "    ax = axs[0]\n",
    "    sns.regplot(data=influx.loc[influx.Circuit == archs[i]], x=\"scaledperturb\", y=\"best_losses\", ax=ax, \n",
    "                ci=None, order=1, color=colors[i], robust=True, scatter_kws={'alpha':0.5})\n",
    "    ax.set_yscale('log')\n",
    "    ax.set_ylabel('Objective Function Value', fontsize=14)\n",
    "    ax.set_xlabel('Perturbation Size, %', fontsize=14)\n",
    "\n",
    "    ax = axs[1]\n",
    "    sns.regplot(data=export.loc[export.Circuit == archs[i]], x=\"scaledperturb\", y=\"best_losses\",  ax=ax, \n",
    "                ci=None, order=1, color=colors[i], robust=True, scatter_kws={'alpha':0.5})\n",
    "    ax.set_yscale('log')\n",
    "    ax.set_ylabel('')\n",
    "    ax.set_xlabel('Perturbation Size, %', fontsize=14)\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig('growth_condition_robustness.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('sundials')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "07c32881fdddda18fc4efdca8ccb6859d747bae1937efa0776c98adbd36477b4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
