{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Import required packages\n",
    "from models import loss_biological, fa_layerednegativemetabolicloop, fa_negativegeneloop, fa_negativemetabolicloop, fa_openloop, fa_openloopintermediate\n",
    "import numpy as np\n",
    "from hyperopt import hp, fmin, tpe\n",
    "from scikits.odes.ode import ode\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Specify if data is to be saved to CSV\n",
    "save_data = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Search space definition\n",
    "space = hp.choice('architecture',\n",
    "    [('Open Loop', hp.uniform('r_lac_ol', 10E-11, 10E-8)),\n",
    "        ('Negative Gene Loop', [hp.uniform('r_tl_ngl', 10E-11, 10E-8),hp.uniform('r_tl_tetR_ngl', 10E-11, 10E-8)]),\n",
    "        ('Negative Metabolic Loop', [hp.uniform('r_fl_prime_nml', 10E-11, 10E-8), hp.uniform('ki_nml', 0., 0.12)]),\n",
    "        ('Layered Negative Metabolic Loop', [hp.uniform('r_tl_lnml', 10E-11, 10E-8), hp.uniform('r_ar2_lnml', 10E-11, 10E-8),])\n",
    "        ])\n",
    "\n",
    "###Objective function\n",
    "def run_opt(max_iters):\n",
    "    losses = []\n",
    "    params = []\n",
    "    circuits = []\n",
    "\n",
    "    def objective(args):\n",
    "        architecture, param_values = args\n",
    "        #Integration conditions\n",
    "        t = np.linspace(0, 5E4, 200)\n",
    "\n",
    "        #Select architecture and generate function\n",
    "        if architecture == 'Open Loop':\n",
    "            ode_function = fa_openloop\n",
    "            y0 = np.array([0., 0., 0., 0.])\n",
    "        elif architecture == 'Negative Gene Loop':\n",
    "            ode_function = fa_negativegeneloop\n",
    "            y0 = np.array([0., 0., 0., 0., 0.])\n",
    "        elif architecture == 'Negative Metabolic Loop':\n",
    "            ode_function = fa_negativemetabolicloop\n",
    "            y0 = np.array([0., 0., 0., 0.])\n",
    "        else:\n",
    "            ode_function = fa_layerednegativemetabolicloop\n",
    "            y0 = np.array([0., 0., 0., 0., 0.])\n",
    "        \n",
    "        extra_options = {'old_api': False, 'user_data': param_values}\n",
    "        ode_solver = ode('cvode', ode_function, **extra_options)\n",
    "        solution = ode_solver.solve(t, y0)\n",
    "\n",
    "        j1 = solution.values.y[-1][-1]\n",
    "        v_prod = solution.values.y[-1][-2]\n",
    "        j1, j2, loss = loss_biological(j1, 1/v_prod, alpha1=10E3, alpha2=10E-2)\n",
    "\n",
    "        losses.append(loss)\n",
    "        params.append(param_values)\n",
    "        circuits.append(architecture)\n",
    "        return loss\n",
    "\n",
    "    #Run hyperopt call\n",
    "    best = fmin(objective, space, algo=tpe.suggest, max_evals=max_iters)\n",
    "    \n",
    "    #Create trajectory data frame\n",
    "    r_lac_ols, r_tl_ngls, r_tl_tetR_ngls, r_fl_prime_nmls, ki_nmls, r_tl_lnmls, r_ar2_lnmls = [[], [], [], [], [], [], []]\n",
    "    for i in range(max_iters):\n",
    "        r_lac_ol, r_tl_ngl, r_tl_tetR_ngl, r_fl_prime_nml, ki_nml, r_tl_lnml, r_ar2_lnml = [np.nan, np.nan, np.nan, np.nan, np.nan, np.nan, np.nan]\n",
    "        arch = circuits[i]\n",
    "        if arch == 'Open Loop':\n",
    "            r_lac_ol = params[i]\n",
    "        elif arch == 'Negative Gene Loop':\n",
    "            r_tl_ngl = params[i][0]\n",
    "            r_tl_tetR_ngl = params[i][1]\n",
    "        elif arch == 'Negative Metabolic Loop':\n",
    "            r_fl_prime_nml = params[i][0]\n",
    "            ki_nml = params[i][1]\n",
    "        else:\n",
    "            r_tl_lnml = params[i][0]\n",
    "            r_ar2_lnml = params[i][1]\n",
    "        \n",
    "        r_lac_ols.append(r_lac_ol)\n",
    "        r_tl_ngls.append(r_tl_ngl)\n",
    "        r_tl_tetR_ngls.append(r_tl_tetR_ngl)\n",
    "        r_fl_prime_nmls.append(r_fl_prime_nml)\n",
    "        ki_nmls.append(ki_nml)\n",
    "        r_tl_lnmls.append(r_tl_lnml)\n",
    "        r_ar2_lnmls.append(r_ar2_lnml)\n",
    "        \n",
    "    landscape = pd.DataFrame({'circuit':circuits, 'loss': losses, 'r_lac_ol':r_lac_ols,\n",
    "            'r_tl_ngl':r_tl_ngls, 'r_tl_tetR_ngl':r_tl_tetR_ngls, 'r_fl_prime_nml':r_fl_prime_nmls,\n",
    "            'ki_nml':ki_nmls, 'r_tl_lnml':r_tl_lnmls, 'r_ar2_lnml':r_ar2_lnmls})    \n",
    "\n",
    "    best_loss = 1E5\n",
    "    best_circuit = 'Initial'\n",
    "    best_losses = []\n",
    "    best_losses_circuits = []\n",
    "    for i in range(len(landscape)):\n",
    "        if landscape.loss[i] < best_loss:\n",
    "            best_loss = landscape.loss[i]\n",
    "            best_circuit = landscape.circuit[i]\n",
    "        best_losses.append(best_loss)\n",
    "        best_losses_circuits.append(best_circuit)\n",
    "    landscape['best_losses'] = best_losses\n",
    "    landscape['best_loss_circuit'] = best_losses_circuits\n",
    "    \n",
    "    return landscape, best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:12<00:00, 77.27trial/s, best loss: 0.1442107202956086] \n"
     ]
    }
   ],
   "source": [
    "###Run sample optimization\n",
    "max_iters = 1000\n",
    "landscape, best = run_opt(max_iters)\n",
    "landscape = landscape.reset_index()\n",
    "if save_data: landscape.to_csv('../data/fatty_acid_sample_run_production_burden.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Search space definition\n",
    "global alpha\n",
    "space = hp.choice('architecture',\n",
    "    [('Open Loop', hp.uniform('r_lac_ol', 10E-11, 10E-8)),\n",
    "        ('Negative Gene Loop', [hp.uniform('r_tl_ngl', 10E-11, 10E-8),hp.uniform('r_tl_tetR_ngl', 10E-11, 10E-8)]),\n",
    "        ('Negative Metabolic Loop', [hp.uniform('r_fl_prime_nml', 10E-11, 10E-8), hp.uniform('ki_nml', 0., 0.12)]),\n",
    "        ('Layered Negative Metabolic Loop', [hp.uniform('r_tl_lnml', 10E-11, 10E-8), hp.uniform('r_ar2_lnml', 10E-11, 10E-8),])\n",
    "        ])\n",
    "\n",
    "###Objective function\n",
    "def run_opt(max_iters):\n",
    "    losses = []\n",
    "    params = []\n",
    "    circuits = []\n",
    "    overshoots = []\n",
    "    rise_times = []\n",
    "\n",
    "    def objective(args):\n",
    "        architecture, param_values = args\n",
    "        #Integration conditions\n",
    "        t = np.linspace(0, 5E4, 200)\n",
    "\n",
    "        #Select architecture and generate function\n",
    "        if architecture == 'Open Loop':\n",
    "            ode_function = fa_openloop\n",
    "            y0 = np.array([0., 0., 0., 0.])\n",
    "        elif architecture == 'Negative Gene Loop':\n",
    "            ode_function = fa_negativegeneloop\n",
    "            y0 = np.array([0., 0., 0., 0., 0.])\n",
    "        elif architecture == 'Negative Metabolic Loop':\n",
    "            ode_function = fa_negativemetabolicloop\n",
    "            y0 = np.array([0., 0., 0., 0.])\n",
    "        else:\n",
    "            ode_function = fa_layerednegativemetabolicloop\n",
    "            y0 = np.array([0., 0., 0., 0., 0.])\n",
    "        \n",
    "        extra_options = {'old_api': False, 'user_data': param_values}\n",
    "        ode_solver = ode('cvode', ode_function, **extra_options)\n",
    "        solution = ode_solver.solve(t, y0)\n",
    "        \n",
    "        ffa_traj = solution.values.y[:, 0]\n",
    "        ffa_ss = solution.values.y[-1][0]\n",
    "        itemindex = np.where(ffa_traj >= ffa_ss*0.5)[0][0]\n",
    "        rise_time = 100*(itemindex/100000) #number of samples\n",
    "        rise_times.append(rise_time)\n",
    "        ffa_max = np.max(ffa_traj)\n",
    "        overshoot = 100*(ffa_max - ffa_ss)/ffa_ss\n",
    "        overshoots.append(overshoot)\n",
    "        loss = overshoot + alpha*rise_time\n",
    "\n",
    "        losses.append(loss)\n",
    "        params.append(param_values)\n",
    "        circuits.append(architecture)\n",
    "        return loss\n",
    "\n",
    "    #Run hyperopt call\n",
    "    best = fmin(objective, space, algo=tpe.suggest, max_evals=max_iters)\n",
    "    \n",
    "    #Create trajectory data frame\n",
    "    r_lac_ols, r_tl_ngls, r_tl_tetR_ngls, r_fl_prime_nmls, ki_nmls, r_tl_lnmls, r_ar2_lnmls = [[], [], [], [], [], [], []]\n",
    "    for i in range(max_iters):\n",
    "        r_lac_ol, r_tl_ngl, r_tl_tetR_ngl, r_fl_prime_nml, ki_nml, r_tl_lnml, r_ar2_lnml = [np.nan, np.nan, np.nan, np.nan, np.nan, np.nan, np.nan]\n",
    "        arch = circuits[i]\n",
    "        if arch == 'Open Loop':\n",
    "            r_lac_ol = params[i]\n",
    "        elif arch == 'Negative Gene Loop':\n",
    "            r_tl_ngl = params[i][0]\n",
    "            r_tl_tetR_ngl = params[i][1]\n",
    "        elif arch == 'Negative Metabolic Loop':\n",
    "            r_fl_prime_nml = params[i][0]\n",
    "            ki_nml = params[i][1]\n",
    "        else:\n",
    "            r_tl_lnml = params[i][0]\n",
    "            r_ar2_lnml = params[i][1]\n",
    "        \n",
    "        r_lac_ols.append(r_lac_ol)\n",
    "        r_tl_ngls.append(r_tl_ngl)\n",
    "        r_tl_tetR_ngls.append(r_tl_tetR_ngl)\n",
    "        r_fl_prime_nmls.append(r_fl_prime_nml)\n",
    "        ki_nmls.append(ki_nml)\n",
    "        r_tl_lnmls.append(r_tl_lnml)\n",
    "        r_ar2_lnmls.append(r_ar2_lnml)\n",
    "        \n",
    "    landscape = pd.DataFrame({'circuit':circuits, 'loss': losses, 'r_lac_ol':r_lac_ols,\n",
    "            'r_tl_ngl':r_tl_ngls, 'r_tl_tetR_ngl':r_tl_tetR_ngls, 'r_fl_prime_nml':r_fl_prime_nmls,\n",
    "            'ki_nml':ki_nmls, 'r_tl_lnml':r_tl_lnmls, 'r_ar2_lnml':r_ar2_lnmls, 'rise_time': rise_times, 'overshoot':overshoots, 'alpha': np.ones(len(overshoots))*alpha})    \n",
    "\n",
    "    best_loss = 1E5\n",
    "    best_circuit = 'Initial'\n",
    "    best_losses = []\n",
    "    best_losses_circuits = []\n",
    "    for i in range(len(landscape)):\n",
    "        if landscape.loss[i] < best_loss:\n",
    "            best_loss = landscape.loss[i]\n",
    "            best_circuit = landscape.circuit[i]\n",
    "        best_losses.append(best_loss)\n",
    "        best_losses_circuits.append(best_circuit)\n",
    "    landscape['best_losses'] = best_losses\n",
    "    landscape['best_loss_circuit'] = best_losses_circuits\n",
    "    \n",
    "    return landscape, best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:01<00:00, 50.79trial/s, best loss: 0.0534]            \n",
      "100%|██████████| 100/100 [00:01<00:00, 76.16trial/s, best loss: 0.0707929869225118] \n",
      "100%|██████████| 100/100 [00:01<00:00, 65.40trial/s, best loss: 0.0938510673672459]\n",
      "100%|██████████| 100/100 [00:02<00:00, 47.59trial/s, best loss: 0.12441942668152085]\n",
      "100%|██████████| 100/100 [00:01<00:00, 78.91trial/s, best loss: 0.16494424805189753]\n",
      "100%|██████████| 100/100 [00:01<00:00, 80.96trial/s, best loss: 0.21866846433111473]\n",
      "100%|██████████| 100/100 [00:01<00:00, 80.58trial/s, best loss: 0.2898912684598941] \n",
      "100%|██████████| 100/100 [00:01<00:00, 70.60trial/s, best loss: 0.3843121493826152] \n",
      "100%|██████████| 100/100 [00:01<00:00, 79.49trial/s, best loss: 0.5094869843708967]\n",
      "100%|██████████| 100/100 [00:01<00:00, 79.15trial/s, best loss: 0.6754326858007279]\n",
      "100%|██████████| 100/100 [00:01<00:00, 81.69trial/s, best loss: 0.8954287882570784]\n",
      "100%|██████████| 100/100 [00:01<00:00, 79.99trial/s, best loss: 1.1870801216689877]\n",
      "100%|██████████| 100/100 [00:01<00:00, 74.39trial/s, best loss: 1.5737256091626661]\n",
      "100%|██████████| 100/100 [00:01<00:00, 78.18trial/s, best loss: 2.0863059263871655]\n",
      "100%|██████████| 100/100 [00:01<00:00, 73.71trial/s, best loss: 2.765839478709466] \n",
      "100%|██████████| 100/100 [00:01<00:00, 80.94trial/s, best loss: 3.666704832322963]\n",
      "100%|██████████| 100/100 [00:01<00:00, 73.07trial/s, best loss: 4.860992270474727]\n",
      "100%|██████████| 100/100 [00:01<00:00, 70.73trial/s, best loss: 6.4442727010140155]\n",
      "100%|██████████| 100/100 [00:01<00:00, 78.61trial/s, best loss: 8.543245562696347]\n",
      "100%|██████████| 100/100 [00:01<00:00, 77.98trial/s, best loss: 11.325877741493816]\n",
      "100%|██████████| 100/100 [00:01<00:00, 71.36trial/s, best loss: 15.014844847182392]\n",
      "100%|██████████| 100/100 [00:01<00:00, 54.49trial/s, best loss: 19.905350466481767]\n",
      "100%|██████████| 100/100 [00:01<00:00, 75.90trial/s, best loss: 25.58589101155095]\n",
      "100%|██████████| 100/100 [00:01<00:00, 81.49trial/s, best loss: 30.90597180792939] \n",
      "100%|██████████| 100/100 [00:01<00:00, 59.05trial/s, best loss: 37.08023275327329] \n",
      "100%|██████████| 100/100 [00:01<00:00, 63.33trial/s, best loss: 44.081079733591]  \n",
      "100%|██████████| 100/100 [00:01<00:00, 75.50trial/s, best loss: 52.1451987377114] \n",
      "100%|██████████| 100/100 [00:01<00:00, 75.23trial/s, best loss: 61.45397655465197]\n",
      "100%|██████████| 100/100 [00:01<00:00, 59.69trial/s, best loss: 72.1602288431063]\n",
      "100%|██████████| 100/100 [00:01<00:00, 61.55trial/s, best loss: 84.57433023925455]\n",
      "100%|██████████| 100/100 [00:01<00:00, 73.80trial/s, best loss: 99.29473313101965] \n",
      "100%|██████████| 100/100 [00:01<00:00, 66.55trial/s, best loss: 116.51484230382164]\n",
      "100%|██████████| 100/100 [00:01<00:00, 77.92trial/s, best loss: 137.16585043443084]\n",
      "100%|██████████| 100/100 [00:01<00:00, 75.35trial/s, best loss: 164.80674547149755]\n",
      "100%|██████████| 100/100 [00:01<00:00, 57.76trial/s, best loss: 189.5751083309257]\n",
      "100%|██████████| 100/100 [00:01<00:00, 78.52trial/s, best loss: 239.2226137662223]\n",
      "100%|██████████| 100/100 [00:01<00:00, 82.64trial/s, best loss: 335.5312529887451]\n",
      "100%|██████████| 100/100 [00:01<00:00, 71.60trial/s, best loss: 465.4880479007121] \n",
      "100%|██████████| 100/100 [00:01<00:00, 76.10trial/s, best loss: 546.8661723925106]\n",
      "100%|██████████| 100/100 [00:01<00:00, 72.06trial/s, best loss: 606.998373460504]\n",
      "100%|██████████| 100/100 [00:01<00:00, 53.65trial/s, best loss: 704.7880424441626]\n",
      "100%|██████████| 100/100 [00:01<00:00, 74.92trial/s, best loss: 809.9663304520652]\n",
      "100%|██████████| 100/100 [00:01<00:00, 76.67trial/s, best loss: 931.1188366029857]\n",
      "100%|██████████| 100/100 [00:01<00:00, 77.66trial/s, best loss: 1054.4735658374898]\n",
      "100%|██████████| 100/100 [00:01<00:00, 59.33trial/s, best loss: 1212.221885464899] \n",
      "100%|██████████| 100/100 [00:01<00:00, 65.10trial/s, best loss: 1381.6259660038263]\n",
      "100%|██████████| 100/100 [00:01<00:00, 61.44trial/s, best loss: 1570.6494915631697]\n",
      "100%|██████████| 100/100 [00:01<00:00, 77.02trial/s, best loss: 1798.3375018585507]\n",
      "100%|██████████| 100/100 [00:01<00:00, 78.12trial/s, best loss: 2087.398469969069] \n",
      "100%|██████████| 100/100 [00:01<00:00, 62.10trial/s, best loss: 2481.5356418642273]\n"
     ]
    }
   ],
   "source": [
    "###Sweep alpha in a logwise fashion\n",
    "alphas = np.logspace(-2, 4, num=50)\n",
    "optimal = pd.DataFrame()\n",
    "for a in alphas:\n",
    "    max_iters = 100\n",
    "    alpha = a\n",
    "    landscape, best = run_opt(max_iters)\n",
    "    landscape = landscape.reset_index()\n",
    "    l_opt = landscape.loc[landscape.loss == landscape.loss.min()]\n",
    "    optimal = pd.concat([optimal, l_opt])\n",
    "optimal.to_csv('../data/fatty_acid_pareto_curve_speed_accuracy.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:01<00:00, 65.31trial/s, best loss: 20.115369230769232]\n",
      "100%|██████████| 100/100 [00:02<00:00, 44.61trial/s, best loss: 20.365938461538462]\n",
      "100%|██████████| 100/100 [00:01<00:00, 75.41trial/s, best loss: 20.616507692307692]\n",
      "100%|██████████| 100/100 [00:01<00:00, 70.58trial/s, best loss: 20.867076923076926]\n",
      "100%|██████████| 100/100 [00:01<00:00, 66.30trial/s, best loss: 21.117646153846156]\n",
      "100%|██████████| 100/100 [00:01<00:00, 75.22trial/s, best loss: 21.368215384615386]\n",
      "100%|██████████| 100/100 [00:01<00:00, 76.73trial/s, best loss: 21.618784615384616]\n",
      "100%|██████████| 100/100 [00:01<00:00, 66.60trial/s, best loss: 21.869353846153846]\n",
      "100%|██████████| 100/100 [00:01<00:00, 74.06trial/s, best loss: 22.11992307692308]\n",
      "100%|██████████| 100/100 [00:01<00:00, 73.02trial/s, best loss: 22.370492307692306]\n",
      "100%|██████████| 100/100 [00:01<00:00, 71.94trial/s, best loss: 22.62106153846154] \n",
      "100%|██████████| 100/100 [00:01<00:00, 66.78trial/s, best loss: 22.871630769230773]\n",
      "100%|██████████| 100/100 [00:01<00:00, 74.52trial/s, best loss: 23.1222]          \n",
      "100%|██████████| 100/100 [00:01<00:00, 72.55trial/s, best loss: 23.372769230769233]\n",
      "100%|██████████| 100/100 [00:01<00:00, 70.97trial/s, best loss: 23.62333846153846]\n",
      "100%|██████████| 100/100 [00:01<00:00, 76.48trial/s, best loss: 23.857419028622495]\n",
      "100%|██████████| 100/100 [00:01<00:00, 61.88trial/s, best loss: 24.01157062754874] \n",
      "100%|██████████| 100/100 [00:01<00:00, 76.52trial/s, best loss: 24.237329917997457]\n",
      "100%|██████████| 100/100 [00:01<00:00, 56.07trial/s, best loss: 24.519757978107837]\n",
      "100%|██████████| 100/100 [00:01<00:00, 76.18trial/s, best loss: 24.80766732132723] \n",
      "100%|██████████| 100/100 [00:01<00:00, 75.80trial/s, best loss: 25.126753846153846]\n",
      "100%|██████████| 100/100 [00:01<00:00, 61.92trial/s, best loss: 24.916000631923687]\n",
      "100%|██████████| 100/100 [00:01<00:00, 75.90trial/s, best loss: 25.191447172071992]\n",
      "100%|██████████| 100/100 [00:01<00:00, 73.04trial/s, best loss: 25.227577551615482]\n",
      "100%|██████████| 100/100 [00:01<00:00, 67.27trial/s, best loss: 25.45782911589651]\n",
      "100%|██████████| 100/100 [00:01<00:00, 74.48trial/s, best loss: 319.0352381582369] \n",
      "100%|██████████| 100/100 [00:01<00:00, 76.47trial/s, best loss: 322.1440668597202]\n",
      "100%|██████████| 100/100 [00:01<00:00, 57.60trial/s, best loss: 357.09321733978896]\n",
      "100%|██████████| 100/100 [00:01<00:00, 76.98trial/s, best loss: 325.1972873699974]\n",
      "100%|██████████| 100/100 [00:01<00:00, 74.73trial/s, best loss: 314.42185251465867]\n",
      "100%|██████████| 100/100 [00:01<00:00, 78.69trial/s, best loss: 325.254351081198] \n",
      "100%|██████████| 100/100 [00:01<00:00, 67.13trial/s, best loss: 349.65034472669345]\n",
      "100%|██████████| 100/100 [00:01<00:00, 78.94trial/s, best loss: 342.0007327229794] \n",
      "100%|██████████| 100/100 [00:01<00:00, 69.75trial/s, best loss: 320.80278639621537]\n",
      "100%|██████████| 100/100 [00:01<00:00, 77.34trial/s, best loss: 416.44971451316553]\n",
      "100%|██████████| 100/100 [00:01<00:00, 65.94trial/s, best loss: 332.94283236666456]\n",
      "100%|██████████| 100/100 [00:01<00:00, 50.20trial/s, best loss: 335.6490422324454]\n",
      "100%|██████████| 100/100 [00:01<00:00, 57.75trial/s, best loss: 375.4048616682083]\n",
      "100%|██████████| 100/100 [00:03<00:00, 26.57trial/s, best loss: 350.53754179289524]\n",
      "100%|██████████| 100/100 [00:02<00:00, 46.46trial/s, best loss: 374.8772739638426]\n",
      "100%|██████████| 100/100 [00:01<00:00, 77.61trial/s, best loss: 380.96110333281]  \n",
      "100%|██████████| 100/100 [00:01<00:00, 73.24trial/s, best loss: 384.3268069425008]\n",
      "100%|██████████| 100/100 [00:01<00:00, 81.11trial/s, best loss: 393.0211024342555]\n",
      "100%|██████████| 100/100 [00:01<00:00, 78.63trial/s, best loss: 420.5290135898069]\n",
      "100%|██████████| 100/100 [00:01<00:00, 72.08trial/s, best loss: 369.0540649933035]\n",
      "100%|██████████| 100/100 [00:01<00:00, 77.74trial/s, best loss: 457.52577609272987]\n",
      "100%|██████████| 100/100 [00:01<00:00, 75.75trial/s, best loss: 398.7305475240433]\n",
      "100%|██████████| 100/100 [00:01<00:00, 74.87trial/s, best loss: 410.33957577268916]\n",
      "100%|██████████| 100/100 [00:01<00:00, 82.14trial/s, best loss: 411.02628518466383]\n",
      "100%|██████████| 100/100 [00:01<00:00, 78.86trial/s, best loss: 387.69032477642946]\n"
     ]
    }
   ],
   "source": [
    "###More closely sample transition zones with linspace\n",
    "alphas = np.linspace(3.72, 4.94, 27)\n",
    "\n",
    "#optimal = pd.DataFrame()\n",
    "for a in alphas[1:-1]:\n",
    "    max_iters = 100\n",
    "    alpha = a\n",
    "    landscape, best = run_opt(max_iters)\n",
    "    landscape = landscape.reset_index()\n",
    "    l_opt = landscape.loc[landscape.loss == landscape.loss.min()]\n",
    "    optimal = pd.concat([optimal, l_opt])\n",
    "\n",
    "alphas = np.linspace(255.95, 339.32, 27)\n",
    "for a in alphas[1:-1]:\n",
    "    max_iters = 100\n",
    "    alpha = a\n",
    "    landscape, best = run_opt(max_iters)\n",
    "    landscape = landscape.reset_index()\n",
    "    l_opt = landscape.loc[landscape.loss == landscape.loss.min()]\n",
    "    optimal = pd.concat([optimal, l_opt])\n",
    "    \n",
    "alphas = np.linspace(275, 10E4, 100)\n",
    "for a in alphas[1:-1]:\n",
    "    max_iters = 100\n",
    "    alpha = a\n",
    "    landscape, best = run_opt(max_iters)\n",
    "    landscape = landscape.reset_index()\n",
    "    l_opt = landscape.loc[landscape.loss == landscape.loss.min()]\n",
    "    optimal = pd.concat([optimal, l_opt])\n",
    "optimal.to_csv('../data/fatty_acid_pareto_curve_speed_accuracy.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(args):\n",
    "    architecture, param_values = args\n",
    "    #Integration conditions\n",
    "    sampling_rate = 10000\n",
    "    t = np.linspace(0, 5E4, sampling_rate)\n",
    "\n",
    "    #Select architecture and generate function\n",
    "    if architecture == 'Open Loop':\n",
    "        ode_function = fa_openloop\n",
    "        y0 = np.array([0., 0., 0., 0.])\n",
    "    elif architecture == 'Negative Gene Loop':\n",
    "        ode_function = fa_negativegeneloop\n",
    "        y0 = np.array([0., 0., 0., 0., 0.])\n",
    "    elif architecture == 'Negative Metabolic Loop':\n",
    "        ode_function = fa_negativemetabolicloop\n",
    "        y0 = np.array([0., 0., 0., 0.])\n",
    "    else:\n",
    "        ode_function = fa_layerednegativemetabolicloop\n",
    "        y0 = np.array([0., 0., 0., 0., 0.])\n",
    "    \n",
    "    extra_options = {'old_api': False, 'user_data': param_values}\n",
    "    ode_solver = ode('cvode', ode_function, **extra_options)\n",
    "    solution = ode_solver.solve(t, y0)\n",
    "    \n",
    "    return solution\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sundials",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "07c32881fdddda18fc4efdca8ccb6859d747bae1937efa0776c98adbd36477b4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
